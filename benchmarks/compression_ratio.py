import matplotlib.pyplot as plt
import numpy as np
import argparse

def calculate_kv_cache(context_length, layers=32, hidden_size=4096, dtype_size=2):
    """
    Calculates KV Cache size in MB based on standard Transformer formula:
    2 * layers * hidden_size * context * dtype_size
    """
    # Standard formula for KV cache memory footprint
    total_bytes = 2 * layers * hidden_size * context_length * dtype_size
    return total_bytes / (1024 * 1024)

def run_theoretical_profile(model_size_gb=3.9):
    """
    Generates a VRAM usage profile comparing Standard vs QKV Aligned allocation
    across increasing context lengths.
    """
    print(f"Running VRAM Profile Analysis for {model_size_gb}GB Base Model...")
    
    # Context lengths to test (from 0 to 8192)
    context_lengths = np.linspace(0, 8192, 100)
    
    # 1. Standard Allocation (Inefficient)
    # Base weight + KV Cache + Fragmentation Overhead (scales with context)
    base_overhead_static = 150 # MB (Runtime kernels, display buffer)
    fragmentation_factor = 1.05 # Standard allocators often waste ~5% due to misalignment
    
    kv_usage = calculate_kv_cache(context_lengths)
    
    standard_vram = (model_size_gb * 1024) + base_overhead_static + (kv_usage * fragmentation_factor)

    # 2. QKV Core Allocation (Surgical)
    # Optimized weight packing + Strictly aligned KV blocks
    # Savings: ~44MB static padding removed + Linear memory scaling (no fragmentation factor)
    
    padding_saved = 44 # MB (From surgical trimming)
    optimized_overhead = 80 # MB (Leaner kernel runtime)
    
    # QKV Core aligns blocks to cache lines, removing the fragmentation multiplier
    qkv_vram = ((model_size_gb * 1024) - padding_saved) + optimized_overhead + kv_usage

    # Plotting
    plt.figure(figsize=(12, 7))
    
    # Plot Standard
    plt.plot(context_lengths, standard_vram, label='Standard Allocator (Frag. Overhead)', 
             color='#e74c3c', linewidth=2, linestyle='-')
    
    # Plot QKV Core
    plt.plot(context_lengths, qkv_vram, label='QKV Core (Surgically Aligned)', 
             color='#27ae60', linewidth=2, linestyle='-')
    
    # Add Limits
    plt.axhline(y=4096, color='black', linestyle='--', linewidth=1.5, label='GTX 1050 Limit (4GB)')
    
    # Fill the "Crash Zone"
    plt.fill_between(context_lengths, standard_vram, 4096, 
                     where=(standard_vram > 4096), 
                     color='#e74c3c', alpha=0.1, label='OOM Crash Zone')

    plt.title(f"VRAM Scaling Analysis: Context Length vs Memory (7B Model)", fontsize=14)
    plt.xlabel("Context Length (Tokens)", fontsize=12)
    plt.ylabel("VRAM Usage (MB)", fontsize=12)
    plt.legend(loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # Annotate the "Sweet Spot"
    # Find where Standard crosses 4GB vs QKV crosses 4GB
    try:
        std_cross = context_lengths[np.where(standard_vram > 4096)[0][0]]
        qkv_cross = context_lengths[np.where(qkv_vram > 4096)[0][0]]
        
        plt.annotate(f'Standard OOM\n@ {int(std_cross)} ctx', 
                     xy=(std_cross, 4096), xytext=(std_cross-1500, 4200),
                     arrowprops=dict(facecolor='red', shrink=0.05))
        
        plt.annotate(f'QKV Extended\n@ {int(qkv_cross)} ctx', 
                     xy=(qkv_cross, 4096), xytext=(qkv_cross+500, 3900),
                     arrowprops=dict(facecolor='green', shrink=0.05))
    except IndexError:
        pass # Curves might not cross in range

    output_file = "vram_scaling_benchmark.png"
    plt.savefig(output_file, dpi=300)
    print(f"âœ… VRAM Profile generated: {output_file}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_size", type=float, default=3.9, help="Model size in GB")
    args = parser.parse_args()
    
    run_theoretical_profile(args.model_size)